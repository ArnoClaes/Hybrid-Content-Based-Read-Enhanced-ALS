{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bWxni05DlDFi"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJPLOKXVlQ2a"
   },
   "source": [
    "#Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43420,
     "status": "ok",
     "timestamp": 1552396003707,
     "user": {
      "displayName": "Lennert Aerts",
      "photoUrl": "",
      "userId": "08865342511418318534"
     },
     "user_tz": -60
    },
    "id": "bU1F1h-YlSp_",
    "outputId": "82d175fa-5ed7-4590-9572-0c67ea23b7c4"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2571,
     "status": "ok",
     "timestamp": 1552396025309,
     "user": {
      "displayName": "Lennert Aerts",
      "photoUrl": "",
      "userId": "08865342511418318534"
     },
     "user_tz": -60
    },
    "id": "3Xi_Dg3q-Y57",
    "outputId": "acd86114-0f33-4c58-c467-c5f4f9df3450"
   },
   "outputs": [],
   "source": [
    "!ls \"/content/drive/My Drive/Knab/Data/CleanData/ALS_inputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AwRrYxV7lxOG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load in pairs\n",
    "df_read_pairs = pd.read_csv(\"/content/drive/My Drive/Knab/Data/CleanData/ALS_inputs/read_pairs.csv\").drop_duplicates() #['URL','clientid_hashed']\n",
    "df_clicked_pairs = pd.read_csv(\"/content/drive/My Drive/Knab/Data/CleanData/ALS_inputs/clicked_pairs.csv\").drop_duplicates()\n",
    "df_article_data = pd.read_csv(\"/content/drive/My Drive/Knab/Data/CleanData/clean_article_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nSnxGFC712kM"
   },
   "outputs": [],
   "source": [
    "#df_read_pairs = df_read_pairs.sort_values(['clientid_hashed', 'URL', 'Confidence_level'], axis = 0).drop_duplicates(['clientid_hashed','URL'],keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9nxUM-qH12kO"
   },
   "outputs": [],
   "source": [
    "df_read_pairs = df_read_pairs.drop_duplicates(['clientid_hashed', 'URL'], keep = 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v54H5p7Q8sCq"
   },
   "source": [
    "#Find useful data, to decrease sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "pvvMcaFo8v3A"
   },
   "outputs": [],
   "source": [
    "#Minimum amount of articles read/clicked\n",
    "lower_bound_client = 7\n",
    "#lower_bound_item = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SR50X3EZ9ple"
   },
   "outputs": [],
   "source": [
    "df_read_count = df_read_pairs['clientid_hashed'].value_counts().reset_index().rename(columns = {'index':'clientid_hashed', 'clientid_hashed':'read_count'})\n",
    "df_read_count['read_count'] = df_read_count['read_count'].astype(int)\n",
    "\n",
    "df_clicked_count = df_clicked_pairs['clientid_hashed'].value_counts().reset_index().rename(columns = {'index':'clientid_hashed', 'clientid_hashed':'clicked_count'}).drop_duplicates()\n",
    "df_clicked_count['clicked_count'] = df_clicked_count['clicked_count'].astype(int)\n",
    "\n",
    "#Part of dataset that meets the requirement\n",
    "df_read_bound = df_read_count[df_read_count['read_count'] >= lower_bound_client]\n",
    "\n",
    "#All the clientids that meet the requirement\n",
    "client_list_read = df_read_bound['clientid_hashed'].values\n",
    "\n",
    "#Add two client lists, as the loops will have to run over the same client lists\n",
    "client_list = client_list_read.tolist()\n",
    "client_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hkdkUKf912kW"
   },
   "outputs": [],
   "source": [
    "df_read_pairs = df_read_pairs[df_read_pairs['clientid_hashed'].isin(client_list)] #Only take data with clients that have >=7 reads\n",
    "df_clicked_pairs = df_clicked_pairs[df_clicked_pairs['clientid_hashed'].isin(client_list)]\n",
    "\n",
    "df_read_items_count = df_read_pairs['URL'].value_counts().reset_index().rename(columns = {'index':'URL', 'URL':'read_count'})\n",
    "\n",
    "item_list_read = df_read_items_count['URL'].values\n",
    "item_list = item_list_read.tolist()\n",
    "item_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UbzmrA-F12kY"
   },
   "outputs": [],
   "source": [
    "#Filter the data to meet the requirement\n",
    "df_read_data = df_read_pairs\n",
    "df_clicked = df_clicked_pairs[(df_clicked_pairs['clientid_hashed'].isin(client_list)) & (df_clicked_pairs['URL'].isin(item_list))]\n",
    "\n",
    "df_test_set = df_read_data.drop_duplicates(['clientid_hashed'], keep = 'last') #take the last read as the test data\n",
    "df_train_set = df_read_data[~df_read_data.isin(df_test_set)].dropna()\n",
    "\n",
    "df_clicked = df_clicked[['URL','clientid_hashed']]\n",
    "df_clicked_testing = pd.merge(left = df_clicked, right = df_test_set, left_on = ['URL', 'clientid_hashed'], right_on = ['URL', 'clientid_hashed'], how = 'left')\n",
    "df_clicked = df_clicked_testing[df_clicked_testing['Confidence_level'].isna()]\n",
    "\n",
    "df_clicked = df_clicked[['URL','clientid_hashed']]\n",
    "df_clicked_training = pd.merge(left = df_clicked, right = df_train_set, left_on = ['URL', 'clientid_hashed'], right_on = ['URL', 'clientid_hashed'], how = 'left')\n",
    "df_clicked = df_clicked_training[df_clicked_training['Confidence_level'].isna()]\n",
    "\n",
    "df_clicked = df_clicked[['URL','clientid_hashed']]\n",
    "df_read = df_train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ucvm1oWjd1vL"
   },
   "source": [
    "#Calculate occurrence matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UQQcp5TdUs15"
   },
   "outputs": [],
   "source": [
    "#Initiate the matrices\n",
    "df_read_matrix = pd.DataFrame(np.zeros([len(client_list),len(item_list)]))\n",
    "df_weightRead_matrix = pd.DataFrame(np.zeros([len(client_list),len(item_list)]))\n",
    "df_clicked_matrix = pd.DataFrame(np.zeros([len(client_list),len(item_list)]))\n",
    "\n",
    "#Loop through all occurrences in read list\n",
    "for i in range(len(df_read)):\n",
    "    url = df_read.iloc[i]['URL']\n",
    "    clientid = df_read.iloc[i]['clientid_hashed']\n",
    "    Conf_L = df_read.iloc[i]['Confidence_level']\n",
    "\n",
    "    #Find location in list\n",
    "    item_loc = item_list.index(url)\n",
    "    client_loc = client_list.index(clientid)\n",
    "\n",
    "    df_read_matrix.loc[df_read_matrix.index == client_loc, item_loc] = 1\n",
    "    df_weightRead_matrix.loc[df_read_matrix.index == client_loc, item_loc] = Conf_L\n",
    "\n",
    "for i in range(len(df_clicked)):\n",
    "    url = df_clicked.iloc[i]['URL']\n",
    "    clientid = df_clicked.iloc[i]['clientid_hashed']\n",
    "\n",
    "    #Find location in list\n",
    "    item_loc = item_list.index(url)\n",
    "    client_loc = client_list.index(clientid)\n",
    "\n",
    "    df_clicked_matrix.loc[df_clicked_matrix.index == client_loc, item_loc] = 1\n",
    "  \n",
    "#Set values of clicked matrix to 0 where both click and read are 1.\n",
    "dup_users = np.where(df_clicked_matrix+df_read_matrix == 2)[0]\n",
    "dup_items = np.where(df_clicked_matrix+df_read_matrix == 2)[1]\n",
    "\n",
    "for i in range(len(dup_users)):\n",
    "    df_clicked_matrix.iloc[dup_users[i]][dup_items[i]] = 0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8909,
     "status": "ok",
     "timestamp": 1552396116859,
     "user": {
      "displayName": "Lennert Aerts",
      "photoUrl": "",
      "userId": "08865342511418318534"
     },
     "user_tz": -60
    },
    "id": "o2a77VmGbR-i",
    "outputId": "06d389d7-1621-4e47-ec9c-538ee11050b5"
   },
   "outputs": [],
   "source": [
    "#Check if matrix has same number of elements in read matrix\n",
    "sum(df_read_matrix.sum()) == len(df_read.drop_duplicates(['URL', 'clientid_hashed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PG5cIw-E7eIz"
   },
   "source": [
    "#ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LnMkkCTG7f2Y"
   },
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "random.seed(sum([ord(c) for c in \"KNAB\"])) #seeding\n",
    "\n",
    "max_epochs = 50 #number of top-level iterations\n",
    "\n",
    "initialize_loc = 0.1 #mean of random initialization\n",
    "intialize_scale = 0.01 #standard deviation of random initialization\n",
    "\n",
    "number_of_clients = len(client_list) \n",
    "number_of_items = len(item_list)\n",
    "\n",
    "factors = 32 #number of factors\n",
    "reg = 2 #Regularization parameter\n",
    "gamma_1 = 0.35\n",
    "gamma_2 = 0.35\n",
    "S_0 = 800 #Weight parameter negative missing\n",
    "alpha = 1 #Weight power parameter negative missing\n",
    "C_0 = 1 #Weight parameter clicked\n",
    "beta = 1 #Weight power parameter clicked\n",
    "w_0 = 1 #Weight of read pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3058,
     "status": "ok",
     "timestamp": 1552396116862,
     "user": {
      "displayName": "Lennert Aerts",
      "photoUrl": "",
      "userId": "08865342511418318534"
     },
     "user_tz": -60
    },
    "id": "ut5B--T312kl",
    "outputId": "10451dc7-8f90-445f-a563-ab7a914be6f7"
   },
   "outputs": [],
   "source": [
    "number_of_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1498,
     "status": "ok",
     "timestamp": 1552396116863,
     "user": {
      "displayName": "Lennert Aerts",
      "photoUrl": "",
      "userId": "08865342511418318534"
     },
     "user_tz": -60
    },
    "id": "Q1-0JZAD12kq",
    "outputId": "7d88c737-b473-4508-a240-28ec39c4f5bd"
   },
   "outputs": [],
   "source": [
    "number_of_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uHccnxcgwG-9"
   },
   "source": [
    "##Initialize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ymrRgszpJiuW"
   },
   "outputs": [],
   "source": [
    "#Randomly initialize factors using normal distribution\n",
    "P = np.random.normal(loc=initialize_loc, scale=intialize_scale, size=[number_of_clients, factors])\n",
    "Q = np.random.normal(loc=initialize_loc, scale=intialize_scale, size=[number_of_items, factors])\n",
    "\n",
    "#Initialize the first R estimations\n",
    "R = df_read_matrix.values\n",
    "\n",
    "#Initialize click training matrix\n",
    "C = df_clicked_matrix.values\n",
    "\n",
    "#Initialize vectors\n",
    "prediction_users = [0]*number_of_clients\n",
    "prediction_users_clicked = [0]*number_of_clients\n",
    "prediction_items = [0]*number_of_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-OTvmmH212kw"
   },
   "outputs": [],
   "source": [
    "#Uniform weighting\n",
    "#S_i = [0] * number_of_items\n",
    "#C_i = [0] * number_of_items\n",
    "\n",
    "#for i in range(number_of_items):\n",
    "#    S_i[i] = S_0 / number_of_items\n",
    "#    C_i[i] = C_0 / number_of_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pO9uJJyeYCbk"
   },
   "source": [
    "##Calculate weights for ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "N6v-lGFRtPz6"
   },
   "outputs": [],
   "source": [
    "#S_i\n",
    "som = 0.\n",
    "Z = 0.\n",
    "p = [0] * number_of_items\n",
    "for i in range(number_of_items):\n",
    "    p[i] = sum(R[:,i])\n",
    "    som += p[i]\n",
    "\n",
    "for i in range(number_of_items):\n",
    "    p[i] /= som\n",
    "    if p[i] > 0:\n",
    "        p[i] = pow(p[i], alpha)\n",
    "    Z += p[i]\n",
    "\n",
    "S_i = [0] * number_of_items\n",
    "Wimin = 0.\n",
    "Wimax = 0.\n",
    "N0 = 0.\n",
    "\n",
    "for i in range(number_of_items):\n",
    "    S_i[i] = S_0 * p[i] / Z\n",
    "    if S_i[i] < Wimin:\n",
    "        Wimin = S_i[i]\n",
    "    if S_i[i] > Wimax:\n",
    "        Wimax = S_i[i]\n",
    "    if S_i[i] == 0:\n",
    "        N0 += 1\n",
    "    \n",
    "    \n",
    "#C_i\n",
    "pv = [0] * number_of_items\n",
    "som1 = 0.\n",
    "Z1 = 0.\n",
    "for i in range(number_of_items):\n",
    "    pv[i] = sum(C[:,i])\n",
    "    som1 += pv[i]\n",
    "\n",
    "for i in range(number_of_items):\n",
    "    pv[i] /= som1\n",
    "    if pv[i] > 0:\n",
    "        pv[i] = pow(pv[i], beta)\n",
    "    Z1 += pv[i]\n",
    "\n",
    "C_i = [0] * number_of_items\n",
    "for i in range(number_of_items):\n",
    "    C_i[i] = C_0 * pv[i] / Z1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTXdAoRmwMyC"
   },
   "source": [
    "##Fast V-ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "19pU2Uw6Osvw"
   },
   "outputs": [],
   "source": [
    "#USER CACHES\n",
    "def caches(P, Q):\n",
    "    C_u = np.zeros(number_of_clients) #Sum of weights clicked per user\n",
    "    V_u = np.zeros(number_of_clients) #Number of clicked per user\n",
    "    R_u = np.zeros(number_of_clients) #Number of read per user\n",
    "    GR =  np.zeros(number_of_clients) #\n",
    "    GvR = np.zeros(number_of_clients) #Cache sum predictions\n",
    "    LvR = np.zeros(number_of_clients) #Cache clicked weighted sum predictions\n",
    "\n",
    "    for u in range(number_of_clients):\n",
    "        val1 = 0.\n",
    "        val2 = 0.\n",
    "\n",
    "        for i in np.where(C[u] == 1)[0]:\n",
    "            C_u[u] += C_i[i]\n",
    "            V_u[u] += 1\n",
    "            val1 += np.dot(P[u], np.transpose(Q[i]))\n",
    "            val2 += C_i[i] * np.dot(P[u], np.transpose(Q[i]))\n",
    "\n",
    "        R_u[u] = sum(R[u])        \n",
    "        GvR[u] = val1\n",
    "        LvR[u] = val2\n",
    "\n",
    "    T = np.dot(np.transpose(P), LvR)\n",
    "    Told = np.copy(T)\n",
    "\n",
    "    DU = np.zeros(factors) #Importance of clicked factors per user\n",
    "    EU = np.dot(np.transpose(P), P) #E users from paper\n",
    "    HU = np.zeros([factors,factors]) \n",
    "\n",
    "    for f in range(factors):\n",
    "        val1 = 0.\n",
    "        for u in range(number_of_clients):\n",
    "            val1 += P[u,f]*C_u[u]\n",
    "        DU[f] = val1\n",
    "        for k in range(f+1):\n",
    "            val = 0.\n",
    "            for u in range(number_of_clients):\n",
    "                val += P[u,f] * P[u,k] * C_u[u]\n",
    "\n",
    "            HU[f,k] = val\n",
    "            HU[k,f] = val\n",
    "\n",
    "    DV = np.zeros(factors) #Importance of clicked factors per item\n",
    "    EV = np.dot(np.transpose(Q), Q) #E users from paper\n",
    "    HV = np.zeros([factors,factors])\n",
    "    for f in range(factors):\n",
    "        val1 = 0.\n",
    "        for i in range(number_of_items):\n",
    "            val1 += Q[i,f]\n",
    "        DV[f] = val1\n",
    "        for k in range(f+1):\n",
    "            val = 0.\n",
    "            for i in range(number_of_items):\n",
    "                val += Q[i,f] * Q[i,k] * S_i[i]\n",
    "\n",
    "            HV[f,k] = val\n",
    "            HV[k,f] = val\n",
    "    return C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7IHlbum8pL1b"
   },
   "outputs": [],
   "source": [
    "# def loss():\n",
    "#   L = reg * (sum(sum(P**2)) + sum(sum(Q**2))) #Regularization part\n",
    "#   for u in range(number_of_clients):\n",
    "#     l = 0.\n",
    "#     for i in np.where(R[u] == 1)[0]:\n",
    "#       pred = np.dot(P[u], np.transpose(Q[i]))\n",
    "#       l += pow(R[u,i] - pred, 2) - S_i[i]*pow(pred,2)\n",
    "#     for i in np.where(C[u] == 1)[0]:\n",
    "#       pred = np.dot(P[u], np.transpose(Q[i]))\n",
    "#       l -= S_i[i] * pow(pred, 2)\n",
    "#       for j in np.where(R[u] == 1)[0]:\n",
    "#         pred_j = np.dot(P[u], np.transpose(Q[j]))\n",
    "#         l += C_i[i] * pow(gamma_1 - (pred_j - pred),2) - pow(gamma_2 - (pred - pred_j),2)\n",
    "#       for j in np.where(C[u] == 1)[0]:\n",
    "#         pred_j = np.dot(P[u], np.transpose(Q[j]))\n",
    "#         l -= C_i[i] * pow(gamma_2 - (pred - pred_j),2)\n",
    "#       for j in range(number_of_items):\n",
    "#         pred_j = np.dot(P[u], np.transpose(Q[j]))\n",
    "#         l += C_i[i] * pow(gamma_2 - (pred - pred_j),2) \n",
    "    \n",
    "#     for i in range(number_of_items):\n",
    "#       pred = np.dot(P[u], np.transpose(Q[i]))\n",
    "#       l += S_i[i] * pow(pred, 2)\n",
    "    \n",
    "#     L += l\n",
    "#   return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "y7m2I8NqrHP7"
   },
   "outputs": [],
   "source": [
    "def loss(C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q):\n",
    "    \n",
    "    L = reg * (sum(sum(P**2)) + sum(sum(Q**2))) #Regularization part\n",
    "    for u in range(number_of_clients):\n",
    "        l = 0.\n",
    "        for i in np.where(R[u] == 1)[0]:\n",
    "            pred = np.dot(P[u], np.transpose(Q[i]))\n",
    "            l += df_weightRead_matrix.values[u,i] * pow(R[u,i] - pred, 2)\n",
    "            l -= S_i[i] * pow(pred, 2)\n",
    "            l -= 2 * C_u[u] * (gamma_1 + gamma_2) * pred\n",
    "\n",
    "        for i in np.where(C[u] == 1)[0]:\n",
    "            pred = np.dot(P[u], np.transpose(Q[i]))\n",
    "            l -= (S_i[i] + C_u[u]) * pow(pred, 2)\n",
    "            l += (number_of_items - V_u[u]) * C_i[i] * pow(pred, 2)\n",
    "            #l -= Cu[u] * pow(pred,2)\n",
    "\n",
    "        for k in range(factors):\n",
    "            l += (2 * gamma_2 * C_u[u] - 2 * LvR[u]) * P[u,k] * DV[k]\n",
    "\n",
    "        l += np.dot(np.dot(HV, P[u]), P[u])\n",
    "        l += C_u[u] * (pow(gamma_1, 2) - pow(gamma_2, 2)) * R_u[u] \n",
    "        l += 2 * (gamma_1 + gamma_2) * R_u[u] * LvR[u] \n",
    "        l -= 2 * C_u[u] * gamma_2 * GvR[u] \n",
    "        l += 2 * GvR[u] * LvR[u] \n",
    "        l += C_u[u] * (number_of_items - V_u[u]) * pow(gamma_2, 2) \n",
    "        l -= 2 * gamma_2 * (number_of_items - V_u[u]) * LvR[u]\n",
    "        l += C_u[u] * np.dot(np.dot(EV, P[u]), P[u])\n",
    "\n",
    "        L += l\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "e9T2kXln0lb5"
   },
   "outputs": [],
   "source": [
    "def update_user(P, Q, u, NN, old_loss):\n",
    "    iter = 1\n",
    "    new_loss = old_loss + 1\n",
    "    P_old = P\n",
    "    Q_old = Q\n",
    "    learning_rate = 2\n",
    "    threshold = 1\n",
    "    \n",
    "    while (new_loss > old_loss and new_loss > 0) or iter == 1:\n",
    "        iter = 0\n",
    "        learning_rate /= 2 \n",
    "        \n",
    "        C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV = caches(P_old, Q_old)\n",
    "        \n",
    "        if learning_rate < threshold:\n",
    "            new_loss = old_loss\n",
    "            break\n",
    "\n",
    "        #Get row from R\n",
    "        rating_items = R[u]\n",
    "        item_list = np.where(rating_items == 1)[0]\n",
    "        w_items = w_0*df_weightRead_matrix.values[u]\n",
    "\n",
    "        #Get row from C\n",
    "        click_items = C[u]\n",
    "        item_click_list = np.where(click_items == 1)[0]\n",
    "\n",
    "        #Memory\n",
    "        old_vector = P[u]\n",
    "\n",
    "        #If the user has not read any articles, return without update\n",
    "        if sum(item_list) == 0:\n",
    "            return\n",
    "\n",
    "        for i in item_list:\n",
    "        # Overwrite 0s from only view predictions, with predicted values from click matrix\n",
    "            prediction_items[i] = np.dot(P[u], np.transpose(Q[i])) \n",
    "\n",
    "        for i in item_click_list:\n",
    "            prediction_items[i] = np.dot(P[u], np.transpose(Q[i]))\n",
    "\n",
    "\n",
    "        for f in range(factors):\n",
    "            numer = 0.\n",
    "            denom = 0.\n",
    "            pd = 0.\n",
    "            for k in range(factors):\n",
    "                if k != f:\n",
    "                    numer += P[u,k] * HV[f,k] + C_u[u] * P[u,k] * EV[f,k]\n",
    "                    pd += P[u,k] * DV[k]\n",
    "\n",
    "            for i in item_list:\n",
    "                prediction_items[i] -=  P[u,f] * Q[i,f] #*learning_rate \n",
    "                numer += -(w_items[i] * rating_items[i] - (w_items[i] - S_i[i]) * prediction_items[i]) * Q[i,f] - (gamma_1 + gamma_2) * C_u[u] * Q[i,f] \n",
    "                denom += (w_items[i] - S_i[i]) * Q[i,f] * Q[i,f]\n",
    "\n",
    "\n",
    "            denom += HV[f,f] + reg\n",
    "\n",
    "\n",
    "            #Initialize counters\n",
    "            cq = 0.\n",
    "            r = 0.\n",
    "            cr = 0.\n",
    "            q = 0.\n",
    "\n",
    "            for i in item_click_list:\n",
    "                prediction_items[i] -=  P[u,f] * Q[i,f] #*learning_rate \n",
    "                numer += -S_i[i] * Q[i,f] * prediction_items[i] \n",
    "                numer += (number_of_items - V_u[u]) * C_i[i] * Q[i,f] * prediction_items[i] \n",
    "                numer += ((gamma_1 + gamma_2) * R_u[u] - gamma_2 * (number_of_items - V_u[u])) * C_i[i] * Q[i,f] \n",
    "                numer -= C_u[u] * Q[i,f] * prediction_items[i] \n",
    "                numer -= gamma_2 * C_u[u] * Q[i,f] \n",
    "                numer -= pd * C_i[i] * Q[i,f] \n",
    "                numer -= C_i[i] * prediction_items[i] * DV[f]\n",
    "\n",
    "                cq += C_i[i] * Q[i,f]\n",
    "                r += prediction_items[i]\n",
    "                cr += C_i[i] * prediction_items[i]\n",
    "                q += Q[i,f]\n",
    "\n",
    "                denom += - S_i[i] * Q[i,f] * Q[i,f] \n",
    "                denom += (number_of_items - V_u[u]) * C_i[i] * Q[i,f] * Q[i,f]\n",
    "                denom -= C_u[u] * Q[i,f] * Q[i,f] \n",
    "                denom -= 2 * C_i[i] * Q[i,f] * DV[f]\n",
    "\n",
    "            numer += cq * r + cr * q + gamma_2 * C_u[u] * DV[f]\n",
    "            denom += C_u[u] * EV[f,f] + 2 * cq * q \n",
    "\n",
    "            #update = P_old[u,f] - learning_rate * (P_old[u,f] - numer/denom)\n",
    "            update = -numer/denom\n",
    "        #Update Factor\n",
    "            if NN == True:\n",
    "                if update >= 0:\n",
    "                    P[u,f] = update\n",
    "                else:\n",
    "                    P[u,f] = 0\n",
    "            else:\n",
    "                P[u,f] = update\n",
    "\n",
    "        #Update Prediction Cache\n",
    "            for i in item_list:\n",
    "                prediction_items[i] += P[u,f] * Q[i,f] #learning_rate * \n",
    "            for i in item_click_list:\n",
    "                prediction_items[i] += P[u,f] * Q[i,f] #learning_rate * \n",
    "        #end for f\n",
    "        \n",
    "        #Update Cache\n",
    "        tmp1 = 0.\n",
    "        tmp2 = 0.\n",
    "        for i in item_click_list:\n",
    "            tmp1 += prediction_items[i]\n",
    "            tmp2 += C_i[i] * prediction_items[i]\n",
    "\n",
    "        GvR[u] = tmp1\n",
    "        LvR[u] = tmp2\n",
    "\n",
    "\n",
    "        for f in range(factors):\n",
    "            val = P[u,f] * LvR[u]\n",
    "            if u == 0:\n",
    "                T[f] = val\n",
    "                Told[f] = val\n",
    "            else:\n",
    "                T[f] += val\n",
    "                Told[f] += val\n",
    "\n",
    "            val0 = DU[f] - old_vector[f] * C_u[u] + P[u,f] * C_u[u]\n",
    "            DU[f] = val0\n",
    "\n",
    "            for k in range(f+1):\n",
    "                val1 = EU[f,k] - old_vector[f] * old_vector[k] + P[u,f] * P[u,k]\n",
    "                EU[f,k] = val1\n",
    "                EU[k,f] = val1\n",
    "\n",
    "                val2 = HU[f,k] - old_vector[f] * old_vector[k] * C_u[u] + P[u,f] * P[u,k] * C_u[u]\n",
    "                HU[f,k] = val2\n",
    "                HU[k,f] = val2\n",
    "\n",
    "            \n",
    "        new_loss = loss(C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q)\n",
    "        diff_loss = old_loss - new_loss\n",
    "                                              \n",
    "        if diff_loss < 0. or new_loss < 0.:\n",
    "            P = np.copy(P_old)\n",
    "            iter=1\n",
    "            \n",
    "    return C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q, new_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "M5QMTkZx1Nxw"
   },
   "outputs": [],
   "source": [
    "def update_item(P, Q, i, NN, old_loss):\n",
    "    iter = 1\n",
    "    new_loss = old_loss + 1\n",
    "    P_old = P\n",
    "    Q_old = Q\n",
    "    learning_rate = 2\n",
    "    threshold = 1\n",
    "  \n",
    "    while (new_loss > old_loss and new_loss > 0) or iter == 1:\n",
    "        iter = 0\n",
    "        learning_rate /= 2 \n",
    "        \n",
    "        C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV = caches(P_old, Q_old)\n",
    "        \n",
    "        if learning_rate < threshold:\n",
    "            new_loss = old_loss\n",
    "            break\n",
    "      \n",
    "        rating_users = R[:,i]\n",
    "        w_users = w_0*df_weightRead_matrix.values[:,i]\n",
    "        user_list = np.where(rating_users == 1)[0]\n",
    "\n",
    "        click_users = C[:,i]\n",
    "        user_click_list = np.where(click_users == 1)[0]\n",
    "\n",
    "        R_i = len(user_list)\n",
    "        V_i = len(user_click_list)\n",
    "        \n",
    "        if R_i == 0:\n",
    "            return\n",
    "        \n",
    "        ## prediction cache for the item\n",
    "        for u in user_list:\n",
    "            prediction_users[u] = np.dot(P[u], np.transpose(Q[i])) \n",
    "\n",
    "        ind_u = np.zeros(V_i, dtype=int)\n",
    "        cnt = 0\n",
    "        GRold = np.zeros(V_i)\n",
    "        GvRold = np.zeros(V_i)\n",
    "        LvRold = np.zeros(V_i)\n",
    "        DVold = 0.\n",
    "\n",
    "        for u in user_click_list:\n",
    "            ind_u[cnt] = u\n",
    "            cnt += 1\n",
    "            prediction_users[u] = np.dot(P[u], np.transpose(Q[i])) \n",
    "            GR[u] = 0\n",
    "            for k in range(factors):\n",
    "                GR[u] += P[u,k] * DV[k]\n",
    "                Told[k] = Told[k] - C_i[i] * P[u,k] * prediction_users[u]\n",
    "\n",
    "        old_vector = Q[i]\n",
    "\n",
    "        for f in range(factors):\n",
    "            for n in range(V_i):\n",
    "                GRold[n] = GR[ind_u[n]] - P[ind_u[n],f] * DV[f]\n",
    "                GvRold[n] = GvR[ind_u[n]] - prediction_users[ind_u[n]]\n",
    "                LvRold[n] = LvR[ind_u[n]] - C_i[i] * prediction_users[ind_u[n]]\n",
    "            DVold = DV[f] - Q[i,f]\n",
    "\n",
    "            numer = 0.\n",
    "            denom = 0.\n",
    "\n",
    "            for k in range(f):\n",
    "                if k != f:\n",
    "                    numer += Q[i,k] * EU[f,k] * S_i[i] \n",
    "                    numer += Q[i,k] * HU[f,k]\n",
    "\n",
    "\n",
    "            for u in user_list:\n",
    "                prediction_users[u] -= P[u,f] * Q[i,f] #learning_rate *\n",
    "                numer += -(w_users[u] * rating_users[u] - (w_users[u] - S_i[i]) * prediction_users[u]) * P[u,f]\n",
    "                numer -= (gamma_1 + gamma_2) * C_u[u] * P[u,f]\n",
    "                denom += (w_users[u] - S_i[i]) * P[u,f] * P[u,f]\n",
    "\n",
    "            denom += S_i[i] * EU[f,f] + HU[f,f] + reg\n",
    "\n",
    "            for u in user_click_list:\n",
    "                prediction_users[u] -= P[u,f] * Q[i,f] #learning_rate *\n",
    "                numer += -S_i[i] * prediction_users[u] * P[u,f] \n",
    "                numer -= C_i[i] * GR[u] * P[u,f] \n",
    "                numer += C_i[i] * GvR[u] * P[u,f] \n",
    "                numer += LvR[u] * P[u,f]\n",
    "                numer += C_i[i] * (prediction_users[u] * (number_of_items - V_u[u]) + (gamma_1 + gamma_2) * R_u[u] - gamma_2 * (number_of_items - V_u[u])) * P[u,f]\n",
    "                numer -= (prediction_users[u] + gamma_2) * C_u[u] * P[u,f]\n",
    "                denom += -S_i[i] * P[u,f]  * P[u,f] \n",
    "                denom += C_i[i] * (number_of_items - V_u[u]) * P[u,f] * P[u,f] \n",
    "                denom -= C_u[u] * P[u,f] * P[u,f]\n",
    "\n",
    "            numer += - T[f] + gamma_2 * DU[f]\n",
    "\n",
    "            #update = Q_old[i,f] - learning_rate * (Q_old[i,f] - numer/denom)\n",
    "            update = -numer/denom\n",
    "        #Update Factor\n",
    "            if NN == True:\n",
    "                if update >= 0:\n",
    "                    Q[i,f] = update\n",
    "                else:\n",
    "                    Q[i,f] = 0\n",
    "            else:\n",
    "                Q[i,f] = update\n",
    "\n",
    "        #Update Prediction Cache\n",
    "        for u in user_list:\n",
    "            prediction_users[u] += P[u,f] * Q[i,f] # learning_rate *\n",
    "\n",
    "        for u in user_click_list:\n",
    "            prediction_users[u] += P[u,f] * Q[i,f] # learning_rate *\n",
    "            \n",
    "        tf = 0.\n",
    "        tfp1 = 0.\n",
    "\n",
    "        fp1 = f + 1\n",
    "\n",
    "        if fp1 >= factors:\n",
    "            fp1 = 0\n",
    "\n",
    "        DV[f] = DVold + Q[i,f]\n",
    "        for n in range(V_i):\n",
    "            GR[ind_u[n]] = GRold[n] + P[ind_u[n],f] * DV[f]\n",
    "            GvR[ind_u[n]] = GvRold[n] + prediction_users[ind_u[n]]\n",
    "            LvR[ind_u[n]] = LvRold[n] + C_i[i] * prediction_users[ind_u[n]]\n",
    "            tf += C_i[i] * P[ind_u[n],f] * prediction_users[ind_u[n]]\n",
    "            tfp1 += C_i[i] * P[ind_u[n],fp1] * prediction_users[ind_u[n]]\n",
    "\n",
    "        Told[f] = T[f] - tf\n",
    "        T[fp1] = Told[fp1] + tfp1\n",
    "\n",
    "        for u in user_click_list:\n",
    "            for k in range(factors):\n",
    "                Told[k] = Told[k] + C_i[i] * P[u,k] * prediction_users[u]\n",
    "\n",
    "        #Update Cache\n",
    "        for f in range(factors):\n",
    "            for k in range(f+1):\n",
    "                val1 = EV[f,k] - old_vector[f] * old_vector[k] + Q[i,f] * Q[i,k]\n",
    "                EV[f,k] = val1\n",
    "                EV[k,f] = val1\n",
    "\n",
    "                val2 = HV[f,k] - old_vector[f] * old_vector[k] * S_i[i] + Q[i,f] * Q[i,k] * S_i[i]\n",
    "                HV[f,k] = val2\n",
    "                HV[k,f] = val2\n",
    "                 \n",
    "        new_loss = loss(C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q)\n",
    "        diff_loss = old_loss - new_loss\n",
    "                                              \n",
    "        if diff_loss < 0. or new_loss < 0.:\n",
    "            Q = np.copy(Q_old)\n",
    "            iter=1\n",
    "            \n",
    "    return C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q, new_loss           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1145049,
     "status": "ok",
     "timestamp": 1552067444140,
     "user": {
      "displayName": "Arno Claes",
      "photoUrl": "",
      "userId": "18358942717775719175"
     },
     "user_tz": -60
    },
    "id": "eaYC8J35Gvht",
    "outputId": "6ebca805-b277-4c7c-f16f-bc612077ef8c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.1\n",
    "diffloss = 1\n",
    "\n",
    "#Top level iteration with stop criterion max epochs\n",
    "C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV = caches(P, Q)\n",
    "oldloss = loss(C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q)\n",
    "print(f'Start loss {oldloss}')\n",
    "j = 0\n",
    "\n",
    "while abs(diffloss) > thresh or abs(iterloss) > thresh:\n",
    "    epochloss = oldloss\n",
    "    \n",
    "    #Update client factors\n",
    "    for u in range(number_of_clients):\n",
    "        Pold, Qold = P, Q\n",
    "        C_u_new, V_u_new, R_u_new, GR_new, GvR_new, LvR_new, T_new, Told_new, EU_new, DU_new, HU_new, EV_new, DV_new, HV_new, P_new, Q_new, newloss = update_user(P, Q, u, NN = False, old_loss = oldloss)\n",
    "\n",
    "        if newloss<oldloss:\n",
    "            P, Q = P_new, Q_new\n",
    "            oldloss = newloss\n",
    "        elif oldloss == newloss:\n",
    "            P, Q = P_new, Q_new\n",
    "        elif oldloss<newloss:\n",
    "            P, Q = Pold, Qold\n",
    "    print(f'P_{j} loss {oldloss}')\n",
    "    userloss = oldloss    \n",
    "  #Update item factors\n",
    "    for i in range(number_of_items):\n",
    "        Pold, Qold = P, Q\n",
    "        C_u_new, V_u_new, R_u_new, GR_new, GvR_new, LvR_new, T_new, Told_new, EU_new, DU_new, HU_new, EV_new, DV_new, HV_new, P_new, Q_new, newloss = update_user(P, Q, u, NN = False, old_loss = oldloss)\n",
    "        \n",
    "        if newloss<oldloss:\n",
    "            P, Q = P_new, Q_new\n",
    "            oldloss = newloss\n",
    "        elif oldloss == newloss:\n",
    "            P, Q = P_new, Q_new\n",
    "        elif oldloss<newloss:\n",
    "            P, Q = Pold, Qold\n",
    "    print(f'Q_{j} loss {oldloss}')\n",
    "    itemloss = oldloss\n",
    "    diffloss = userloss - itemloss\n",
    "    iterloss = epochloss - itemloss\n",
    "    j += 1\n",
    "\n",
    "else:\n",
    "    print(f'Convergence after {j} iterations')\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jfD8stPs12lG"
   },
   "outputs": [],
   "source": [
    "R_est = np.dot(P,np.transpose(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Esj6cXJk12lJ"
   },
   "outputs": [],
   "source": [
    "np.savez(\"/content/drive/My Drive/Knab/Data/CleanData/ALS_inputs/P_matrix_15.npz\",P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "b5VLePOK12lO"
   },
   "outputs": [],
   "source": [
    "np.savez(\"/content/drive/My Drive/Knab/Data/CleanData/ALS_inputs/Q_matrix_15.npz\", Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6PZvDVvy12lS"
   },
   "outputs": [],
   "source": [
    "for i in range(len(client_list)):\n",
    "    read_articles = R[i]\n",
    "    clicked_articles = C[i]\n",
    "    for j in range(len(item_list)):\n",
    "        if read_articles[j] == 1:\n",
    "            R_est[i,j] = 0\n",
    "        elif clicked_articles[j] == 1:\n",
    "            R_est[i,j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fwlAW-E412lU"
   },
   "outputs": [],
   "source": [
    "hitrate = np.zeros(len(range(3,11)))\n",
    "cnt = 0\n",
    "for j in range(3,11):\n",
    "    test_item_loc = np.zeros(len(df_test_set), dtype= int) #location of items in R_est\n",
    "    test_client_loc = np.zeros(len(df_test_set), dtype= int) #location of users in R_est\n",
    "    test_R_est = np.zeros(len(df_test_set)) #estimated rating of user-item pair\n",
    "    max_indices_test = [] #list for indices of top-N rated articles\n",
    "\n",
    "    hit = 0\n",
    "    for i in range(len(df_test_set)):\n",
    "        url = df_test_set.iloc[i]['URL'] #take url of row in test set\n",
    "        clientid = df_test_set.iloc[i]['clientid_hashed'] #take clientid of row in test set\n",
    "\n",
    "        #Find location in list and value in estimated ratings\n",
    "        test_item_loc[i] = item_list.index(url) #take index for the url\n",
    "        test_client_loc[i] = client_list.index(clientid) #take index for the client\n",
    "        user_ratings = R_est[test_client_loc[i]] #take ratings for this client\n",
    "        test_R_est[i] = R_est[test_client_loc[i],test_item_loc[i]] #store rating for the client-item pair\n",
    "\n",
    "        #Find top-N rated articles in estimated ratings for users\n",
    "        max_indices_test.append(user_ratings.argsort()[-j:][::-1]) #store top-n ratings of this client\n",
    "        if test_item_loc[i] in max_indices_test[i]:\n",
    "            hit += 1\n",
    "    \n",
    "    hitrate[cnt] = hit/len(df_test_set)\n",
    "    max_indices_test =  np.array([max_indices_test])[0]\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQf6P7rV12lb",
    "outputId": "2879f3e9-bf7e-49dc-9414-197942ca1c8c"
   },
   "outputs": [],
   "source": [
    "hitrate"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FastALS.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
