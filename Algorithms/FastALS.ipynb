{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FastALS.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"colab_type":"code","id":"bWxni05DlDFi","colab":{}},"cell_type":"code","source":["import glob\n","import pandas as pd\n","from google.colab import files\n","from google.colab import drive\n","import numpy as np\n","import scipy as sc\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import re\n","import random\n","import sys\n","import math\n","import warnings\n","warnings.filterwarnings('ignore')\n","import seaborn as sns\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"WJPLOKXVlQ2a"},"cell_type":"markdown","source":["#Load in data"]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1552396003707,"user_tz":-60,"elapsed":43420,"user":{"displayName":"Lennert Aerts","photoUrl":"","userId":"08865342511418318534"}},"id":"bU1F1h-YlSp_","outputId":"82d175fa-5ed7-4590-9572-0c67ea23b7c4","colab":{"base_uri":"https://localhost:8080/","height":189}},"cell_type":"code","source":["drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","collapsed":true,"executionInfo":{"status":"ok","timestamp":1552396025309,"user_tz":-60,"elapsed":2571,"user":{"displayName":"Lennert Aerts","photoUrl":"","userId":"08865342511418318534"}},"id":"3Xi_Dg3q-Y57","outputId":"acd86114-0f33-4c58-c467-c5f4f9df3450","colab":{"base_uri":"https://localhost:8080/","height":114}},"cell_type":"code","source":["!ls \"/content/drive/My Drive/Knab/Data/CleanData/ALS_inputs\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["ClickedMatrix500.csv  P_matrix_20.npz\t read_pairs.csv\n","clicked_pairs.csv     Q_matrix_15.npz\t WeightReadMatrix500.csv\n","MissingMatrix500.csv  Q_matrix_20.npz\n","P_matrix_15.npz       ReadMatrix500.csv\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"AwRrYxV7lxOG","scrolled":true,"colab":{}},"cell_type":"code","source":["#Load in pairs\n","df_read_pairs = pd.read_csv(\"/content/drive/My Drive/Knab/Data/CleanData/ALS_inputs/read_pairs.csv\").drop_duplicates() #['URL','clientid_hashed']\n","df_clicked_pairs = pd.read_csv(\"/content/drive/My Drive/Knab/Data/CleanData/ALS_inputs/clicked_pairs.csv\").drop_duplicates()\n","df_article_data = pd.read_csv(\"/content/drive/My Drive/Knab/Data/CleanData/clean_article_data.csv\")"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"nSnxGFC712kM","colab":{}},"cell_type":"code","source":["#df_read_pairs = df_read_pairs.sort_values(['clientid_hashed', 'URL', 'Confidence_level'], axis = 0).drop_duplicates(['clientid_hashed','URL'],keep='last')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"9nxUM-qH12kO","colab":{}},"cell_type":"code","source":["df_read_pairs = df_read_pairs.drop_duplicates(['clientid_hashed', 'URL'], keep = 'last')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"v54H5p7Q8sCq"},"cell_type":"markdown","source":["#Find useful data, to decrease sparsity"]},{"metadata":{"colab_type":"code","id":"pvvMcaFo8v3A","colab":{}},"cell_type":"code","source":["#Minimum amount of articles read/clicked\n","lower_bound_client = 7\n","#lower_bound_item = 7"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"SR50X3EZ9ple","colab":{}},"cell_type":"code","source":["df_read_count = df_read_pairs['clientid_hashed'].value_counts().reset_index().rename(columns = {'index':'clientid_hashed', 'clientid_hashed':'read_count'})\n","df_read_count['read_count'] = df_read_count['read_count'].astype(int)\n","\n","df_clicked_count = df_clicked_pairs['clientid_hashed'].value_counts().reset_index().rename(columns = {'index':'clientid_hashed', 'clientid_hashed':'clicked_count'}).drop_duplicates()\n","df_clicked_count['clicked_count'] = df_clicked_count['clicked_count'].astype(int)\n","\n","#Part of dataset that meets the requirement\n","df_read_bound = df_read_count[df_read_count['read_count'] >= lower_bound_client]\n","\n","#All the clientids that meet the requirement\n","client_list_read = df_read_bound['clientid_hashed'].values\n","\n","#Add two client lists, as the loops will have to run over the same client lists\n","client_list = client_list_read.tolist()\n","client_list.sort()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"hkdkUKf912kW","colab":{}},"cell_type":"code","source":["df_read_pairs = df_read_pairs[df_read_pairs['clientid_hashed'].isin(client_list)] #Only take data with clients that have >=7 reads\n","df_clicked_pairs = df_clicked_pairs[df_clicked_pairs['clientid_hashed'].isin(client_list)]\n","\n","df_read_items_count = df_read_pairs['URL'].value_counts().reset_index().rename(columns = {'index':'URL', 'URL':'read_count'})\n","\n","item_list_read = df_read_items_count['URL'].values\n","item_list = item_list_read.tolist()\n","item_list.sort()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"UbzmrA-F12kY","colab":{}},"cell_type":"code","source":["#Filter the data to meet the requirement\n","df_read_data = df_read_pairs\n","df_clicked = df_clicked_pairs[(df_clicked_pairs['clientid_hashed'].isin(client_list)) & (df_clicked_pairs['URL'].isin(item_list))]\n","\n","df_test_set = df_read_data.drop_duplicates(['clientid_hashed'], keep = 'last') #take the last read as the test data\n","df_train_set = df_read_data[~df_read_data.isin(df_test_set)].dropna()\n","\n","df_clicked = df_clicked[['URL','clientid_hashed']]\n","df_clicked_testing = pd.merge(left = df_clicked, right = df_test_set, left_on = ['URL', 'clientid_hashed'], right_on = ['URL', 'clientid_hashed'], how = 'left')\n","df_clicked = df_clicked_testing[df_clicked_testing['Confidence_level'].isna()]\n","\n","df_clicked = df_clicked[['URL','clientid_hashed']]\n","df_clicked_training = pd.merge(left = df_clicked, right = df_train_set, left_on = ['URL', 'clientid_hashed'], right_on = ['URL', 'clientid_hashed'], how = 'left')\n","df_clicked = df_clicked_training[df_clicked_training['Confidence_level'].isna()]\n","\n","df_clicked = df_clicked[['URL','clientid_hashed']]\n","df_read = df_train_set"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"Ucvm1oWjd1vL"},"cell_type":"markdown","source":["#Calculate occurrence matrices"]},{"metadata":{"colab_type":"code","id":"UQQcp5TdUs15","colab":{}},"cell_type":"code","source":["#Initiate the matrices\n","df_read_matrix = pd.DataFrame(np.zeros([len(client_list),len(item_list)]))\n","df_weightRead_matrix = pd.DataFrame(np.zeros([len(client_list),len(item_list)]))\n","df_clicked_matrix = pd.DataFrame(np.zeros([len(client_list),len(item_list)]))\n","\n","#Loop through all occurrences in read list\n","for i in range(len(df_read)):\n","    url = df_read.iloc[i]['URL']\n","    clientid = df_read.iloc[i]['clientid_hashed']\n","    Conf_L = df_read.iloc[i]['Confidence_level']\n","\n","    #Find location in list\n","    item_loc = item_list.index(url)\n","    client_loc = client_list.index(clientid)\n","\n","    df_read_matrix.loc[df_read_matrix.index == client_loc, item_loc] = 1\n","    df_weightRead_matrix.loc[df_read_matrix.index == client_loc, item_loc] = Conf_L\n","\n","for i in range(len(df_clicked)):\n","    url = df_clicked.iloc[i]['URL']\n","    clientid = df_clicked.iloc[i]['clientid_hashed']\n","\n","    #Find location in list\n","    item_loc = item_list.index(url)\n","    client_loc = client_list.index(clientid)\n","\n","    df_clicked_matrix.loc[df_clicked_matrix.index == client_loc, item_loc] = 1\n","  \n","#Set values of clicked matrix to 0 where both click and read are 1.\n","dup_users = np.where(df_clicked_matrix+df_read_matrix == 2)[0]\n","dup_items = np.where(df_clicked_matrix+df_read_matrix == 2)[1]\n","\n","for i in range(len(dup_users)):\n","    df_clicked_matrix.iloc[dup_users[i]][dup_items[i]] = 0\n"," "],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1552396116859,"user_tz":-60,"elapsed":8909,"user":{"displayName":"Lennert Aerts","photoUrl":"","userId":"08865342511418318534"}},"id":"o2a77VmGbR-i","outputId":"06d389d7-1621-4e47-ec9c-538ee11050b5","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#Check if matrix has same number of elements in read matrix\n","sum(df_read_matrix.sum()) == len(df_read.drop_duplicates(['URL', 'clientid_hashed']))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":21}]},{"metadata":{"colab_type":"text","id":"PG5cIw-E7eIz"},"cell_type":"markdown","source":["#ALS"]},{"metadata":{"colab_type":"code","id":"LnMkkCTG7f2Y","colab":{}},"cell_type":"code","source":["#Hyper parameters\n","random.seed(sum([ord(c) for c in \"KNAB\"])) #seeding\n","\n","max_epochs = 50 #number of top-level iterations\n","\n","initialize_loc = 0.1 #mean of random initialization\n","intialize_scale = 0.01 #standard deviation of random initialization\n","\n","number_of_clients = len(client_list) \n","number_of_items = len(item_list)\n","\n","factors = 32 #number of factors\n","reg = 2 #Regularization parameter\n","gamma_1 = 0.35\n","gamma_2 = 0.35\n","S_0 = 800 #Weight parameter negative missing\n","alpha = 1 #Weight power parameter negative missing\n","C_0 = 1 #Weight parameter clicked\n","beta = 1 #Weight power parameter clicked\n","w_0 = 1 #Weight of read pairs"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1552396116862,"user_tz":-60,"elapsed":3058,"user":{"displayName":"Lennert Aerts","photoUrl":"","userId":"08865342511418318534"}},"id":"ut5B--T312kl","outputId":"10451dc7-8f90-445f-a563-ab7a914be6f7","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["number_of_clients"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["375"]},"metadata":{"tags":[]},"execution_count":23}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1552396116863,"user_tz":-60,"elapsed":1498,"user":{"displayName":"Lennert Aerts","photoUrl":"","userId":"08865342511418318534"}},"id":"Q1-0JZAD12kq","outputId":"7d88c737-b473-4508-a240-28ec39c4f5bd","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["number_of_items"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["509"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"colab_type":"text","id":"uHccnxcgwG-9"},"cell_type":"markdown","source":["##Initialize values"]},{"metadata":{"colab_type":"code","id":"ymrRgszpJiuW","colab":{}},"cell_type":"code","source":["#Randomly initialize factors using normal distribution\n","P = np.random.normal(loc=initialize_loc, scale=intialize_scale, size=[number_of_clients, factors])\n","Q = np.random.normal(loc=initialize_loc, scale=intialize_scale, size=[number_of_items, factors])\n","\n","#Initialize the first R estimations\n","R = df_read_matrix.values\n","\n","#Initialize click training matrix\n","C = df_clicked_matrix.values\n","\n","#Initialize vectors\n","prediction_users = [0]*number_of_clients\n","prediction_users_clicked = [0]*number_of_clients\n","prediction_items = [0]*number_of_items"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"-OTvmmH212kw","colab":{}},"cell_type":"code","source":["#Uniform weighting\n","#S_i = [0] * number_of_items\n","#C_i = [0] * number_of_items\n","\n","#for i in range(number_of_items):\n","#    S_i[i] = S_0 / number_of_items\n","#    C_i[i] = C_0 / number_of_items"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"pO9uJJyeYCbk"},"cell_type":"markdown","source":["##Calculate weights for ALS"]},{"metadata":{"colab_type":"code","id":"N6v-lGFRtPz6","colab":{}},"cell_type":"code","source":["#S_i\n","som = 0.\n","Z = 0.\n","p = [0] * number_of_items\n","for i in range(number_of_items):\n","    p[i] = sum(R[:,i])\n","    som += p[i]\n","\n","for i in range(number_of_items):\n","    p[i] /= som\n","    if p[i] > 0:\n","        p[i] = pow(p[i], alpha)\n","    Z += p[i]\n","\n","S_i = [0] * number_of_items\n","Wimin = 0.\n","Wimax = 0.\n","N0 = 0.\n","\n","for i in range(number_of_items):\n","    S_i[i] = S_0 * p[i] / Z\n","    if S_i[i] < Wimin:\n","        Wimin = S_i[i]\n","    if S_i[i] > Wimax:\n","        Wimax = S_i[i]\n","    if S_i[i] == 0:\n","        N0 += 1\n","    \n","    \n","#C_i\n","pv = [0] * number_of_items\n","som1 = 0.\n","Z1 = 0.\n","for i in range(number_of_items):\n","    pv[i] = sum(C[:,i])\n","    som1 += pv[i]\n","\n","for i in range(number_of_items):\n","    pv[i] /= som1\n","    if pv[i] > 0:\n","        pv[i] = pow(pv[i], beta)\n","    Z1 += pv[i]\n","\n","C_i = [0] * number_of_items\n","for i in range(number_of_items):\n","    C_i[i] = C_0 * pv[i] / Z1"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"yTXdAoRmwMyC"},"cell_type":"markdown","source":["##Fast V-ALS"]},{"metadata":{"colab_type":"code","id":"19pU2Uw6Osvw","colab":{}},"cell_type":"code","source":["#USER CACHES\n","def caches(P, Q):\n","    C_u = np.zeros(number_of_clients) #Sum of weights clicked per user\n","    V_u = np.zeros(number_of_clients) #Number of clicked per user\n","    R_u = np.zeros(number_of_clients) #Number of read per user\n","    GR =  np.zeros(number_of_clients) #\n","    GvR = np.zeros(number_of_clients) #Cache sum predictions\n","    LvR = np.zeros(number_of_clients) #Cache clicked weighted sum predictions\n","\n","    for u in range(number_of_clients):\n","        val1 = 0.\n","        val2 = 0.\n","\n","        for i in np.where(C[u] == 1)[0]:\n","            C_u[u] += C_i[i]\n","            V_u[u] += 1\n","            val1 += np.dot(P[u], np.transpose(Q[i]))\n","            val2 += C_i[i] * np.dot(P[u], np.transpose(Q[i]))\n","\n","        R_u[u] = sum(R[u])        \n","        GvR[u] = val1\n","        LvR[u] = val2\n","\n","    T = np.dot(np.transpose(P), LvR)\n","    Told = np.copy(T)\n","\n","    DU = np.zeros(factors) #Importance of clicked factors per user\n","    EU = np.dot(np.transpose(P), P) #E users from paper\n","    HU = np.zeros([factors,factors]) \n","\n","    for f in range(factors):\n","        val1 = 0.\n","        for u in range(number_of_clients):\n","            val1 += P[u,f]*C_u[u]\n","        DU[f] = val1\n","        for k in range(f+1):\n","            val = 0.\n","            for u in range(number_of_clients):\n","                val += P[u,f] * P[u,k] * C_u[u]\n","\n","            HU[f,k] = val\n","            HU[k,f] = val\n","\n","    DV = np.zeros(factors) #Importance of clicked factors per item\n","    EV = np.dot(np.transpose(Q), Q) #E users from paper\n","    HV = np.zeros([factors,factors])\n","    for f in range(factors):\n","        val1 = 0.\n","        for i in range(number_of_items):\n","            val1 += Q[i,f]\n","        DV[f] = val1\n","        for k in range(f+1):\n","            val = 0.\n","            for i in range(number_of_items):\n","                val += Q[i,f] * Q[i,k] * S_i[i]\n","\n","            HV[f,k] = val\n","            HV[k,f] = val\n","    return C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"7IHlbum8pL1b","colab":{}},"cell_type":"code","source":["# def loss():\n","#   L = reg * (sum(sum(P**2)) + sum(sum(Q**2))) #Regularization part\n","#   for u in range(number_of_clients):\n","#     l = 0.\n","#     for i in np.where(R[u] == 1)[0]:\n","#       pred = np.dot(P[u], np.transpose(Q[i]))\n","#       l += pow(R[u,i] - pred, 2) - S_i[i]*pow(pred,2)\n","#     for i in np.where(C[u] == 1)[0]:\n","#       pred = np.dot(P[u], np.transpose(Q[i]))\n","#       l -= S_i[i] * pow(pred, 2)\n","#       for j in np.where(R[u] == 1)[0]:\n","#         pred_j = np.dot(P[u], np.transpose(Q[j]))\n","#         l += C_i[i] * pow(gamma_1 - (pred_j - pred),2) - pow(gamma_2 - (pred - pred_j),2)\n","#       for j in np.where(C[u] == 1)[0]:\n","#         pred_j = np.dot(P[u], np.transpose(Q[j]))\n","#         l -= C_i[i] * pow(gamma_2 - (pred - pred_j),2)\n","#       for j in range(number_of_items):\n","#         pred_j = np.dot(P[u], np.transpose(Q[j]))\n","#         l += C_i[i] * pow(gamma_2 - (pred - pred_j),2) \n","    \n","#     for i in range(number_of_items):\n","#       pred = np.dot(P[u], np.transpose(Q[i]))\n","#       l += S_i[i] * pow(pred, 2)\n","    \n","#     L += l\n","#   return L"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"y7m2I8NqrHP7","colab":{}},"cell_type":"code","source":["def loss(C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q):\n","    \n","    L = reg * (sum(sum(P**2)) + sum(sum(Q**2))) #Regularization part\n","    for u in range(number_of_clients):\n","        l = 0.\n","        for i in np.where(R[u] == 1)[0]:\n","            pred = np.dot(P[u], np.transpose(Q[i]))\n","            l += df_weightRead_matrix.values[u,i] * pow(R[u,i] - pred, 2)\n","            l -= S_i[i] * pow(pred, 2)\n","            l -= 2 * C_u[u] * (gamma_1 + gamma_2) * pred\n","\n","        for i in np.where(C[u] == 1)[0]:\n","            pred = np.dot(P[u], np.transpose(Q[i]))\n","            l -= (S_i[i] + C_u[u]) * pow(pred, 2)\n","            l += (number_of_items - V_u[u]) * C_i[i] * pow(pred, 2)\n","            #l -= Cu[u] * pow(pred,2)\n","\n","        for k in range(factors):\n","            l += (2 * gamma_2 * C_u[u] - 2 * LvR[u]) * P[u,k] * DV[k]\n","\n","        l += np.dot(np.dot(HV, P[u]), P[u])\n","        l += C_u[u] * (pow(gamma_1, 2) - pow(gamma_2, 2)) * R_u[u] \n","        l += 2 * (gamma_1 + gamma_2) * R_u[u] * LvR[u] \n","        l -= 2 * C_u[u] * gamma_2 * GvR[u] \n","        l += 2 * GvR[u] * LvR[u] \n","        l += C_u[u] * (number_of_items - V_u[u]) * pow(gamma_2, 2) \n","        l -= 2 * gamma_2 * (number_of_items - V_u[u]) * LvR[u]\n","        l += C_u[u] * np.dot(np.dot(EV, P[u]), P[u])\n","\n","        L += l\n","\n","    return L"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"e9T2kXln0lb5","colab":{}},"cell_type":"code","source":["def update_user(P, Q, u, NN, old_loss):\n","    iter = 1\n","    new_loss = old_loss + 1\n","    P_old = P\n","    Q_old = Q\n","    learning_rate = 2\n","    threshold = 1\n","    \n","    while (new_loss > old_loss and new_loss > 0) or iter == 1:\n","        iter = 0\n","        learning_rate /= 2 \n","        \n","        C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV = caches(P_old, Q_old)\n","        \n","        if learning_rate < threshold:\n","            new_loss = old_loss\n","            break\n","\n","        #Get row from R\n","        rating_items = R[u]\n","        item_list = np.where(rating_items == 1)[0]\n","        w_items = w_0*df_weightRead_matrix.values[u]\n","\n","        #Get row from C\n","        click_items = C[u]\n","        item_click_list = np.where(click_items == 1)[0]\n","\n","        #Memory\n","        old_vector = P[u]\n","\n","        #If the user has not read any articles, return without update\n","        if sum(item_list) == 0:\n","            return\n","\n","        for i in item_list:\n","        # Overwrite 0s from only view predictions, with predicted values from click matrix\n","            prediction_items[i] = np.dot(P[u], np.transpose(Q[i])) \n","\n","        for i in item_click_list:\n","            prediction_items[i] = np.dot(P[u], np.transpose(Q[i]))\n","\n","\n","        for f in range(factors):\n","            numer = 0.\n","            denom = 0.\n","            pd = 0.\n","            for k in range(factors):\n","                if k != f:\n","                    numer += P[u,k] * HV[f,k] + C_u[u] * P[u,k] * EV[f,k]\n","                    pd += P[u,k] * DV[k]\n","\n","            for i in item_list:\n","                prediction_items[i] -=  P[u,f] * Q[i,f] #*learning_rate \n","                numer += -(w_items[i] * rating_items[i] - (w_items[i] - S_i[i]) * prediction_items[i]) * Q[i,f] - (gamma_1 + gamma_2) * C_u[u] * Q[i,f] \n","                denom += (w_items[i] - S_i[i]) * Q[i,f] * Q[i,f]\n","\n","\n","            denom += HV[f,f] + reg\n","\n","\n","            #Initialize counters\n","            cq = 0.\n","            r = 0.\n","            cr = 0.\n","            q = 0.\n","\n","            for i in item_click_list:\n","                prediction_items[i] -=  P[u,f] * Q[i,f] #*learning_rate \n","                numer += -S_i[i] * Q[i,f] * prediction_items[i] \n","                numer += (number_of_items - V_u[u]) * C_i[i] * Q[i,f] * prediction_items[i] \n","                numer += ((gamma_1 + gamma_2) * R_u[u] - gamma_2 * (number_of_items - V_u[u])) * C_i[i] * Q[i,f] \n","                numer -= C_u[u] * Q[i,f] * prediction_items[i] \n","                numer -= gamma_2 * C_u[u] * Q[i,f] \n","                numer -= pd * C_i[i] * Q[i,f] \n","                numer -= C_i[i] * prediction_items[i] * DV[f]\n","\n","                cq += C_i[i] * Q[i,f]\n","                r += prediction_items[i]\n","                cr += C_i[i] * prediction_items[i]\n","                q += Q[i,f]\n","\n","                denom += - S_i[i] * Q[i,f] * Q[i,f] \n","                denom += (number_of_items - V_u[u]) * C_i[i] * Q[i,f] * Q[i,f]\n","                denom -= C_u[u] * Q[i,f] * Q[i,f] \n","                denom -= 2 * C_i[i] * Q[i,f] * DV[f]\n","\n","            numer += cq * r + cr * q + gamma_2 * C_u[u] * DV[f]\n","            denom += C_u[u] * EV[f,f] + 2 * cq * q \n","\n","            #update = P_old[u,f] - learning_rate * (P_old[u,f] - numer/denom)\n","            update = -numer/denom\n","        #Update Factor\n","            if NN == True:\n","                if update >= 0:\n","                    P[u,f] = update\n","                else:\n","                    P[u,f] = 0\n","            else:\n","                P[u,f] = update\n","\n","        #Update Prediction Cache\n","            for i in item_list:\n","                prediction_items[i] += P[u,f] * Q[i,f] #learning_rate * \n","            for i in item_click_list:\n","                prediction_items[i] += P[u,f] * Q[i,f] #learning_rate * \n","        #end for f\n","        \n","        #Update Cache\n","        tmp1 = 0.\n","        tmp2 = 0.\n","        for i in item_click_list:\n","            tmp1 += prediction_items[i]\n","            tmp2 += C_i[i] * prediction_items[i]\n","\n","        GvR[u] = tmp1\n","        LvR[u] = tmp2\n","\n","\n","        for f in range(factors):\n","            val = P[u,f] * LvR[u]\n","            if u == 0:\n","                T[f] = val\n","                Told[f] = val\n","            else:\n","                T[f] += val\n","                Told[f] += val\n","\n","            val0 = DU[f] - old_vector[f] * C_u[u] + P[u,f] * C_u[u]\n","            DU[f] = val0\n","\n","            for k in range(f+1):\n","                val1 = EU[f,k] - old_vector[f] * old_vector[k] + P[u,f] * P[u,k]\n","                EU[f,k] = val1\n","                EU[k,f] = val1\n","\n","                val2 = HU[f,k] - old_vector[f] * old_vector[k] * C_u[u] + P[u,f] * P[u,k] * C_u[u]\n","                HU[f,k] = val2\n","                HU[k,f] = val2\n","\n","            \n","        new_loss = loss(C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q)\n","        diff_loss = old_loss - new_loss\n","                                              \n","        if diff_loss < 0. or new_loss < 0.:\n","            P = np.copy(P_old)\n","            iter=1\n","            \n","    return C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q, new_loss"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"M5QMTkZx1Nxw","colab":{}},"cell_type":"code","source":["def update_item(P, Q, i, NN, old_loss):\n","    iter = 1\n","    new_loss = old_loss + 1\n","    P_old = P\n","    Q_old = Q\n","    learning_rate = 2\n","    threshold = 1\n","  \n","    while (new_loss > old_loss and new_loss > 0) or iter == 1:\n","        iter = 0\n","        learning_rate /= 2 \n","        \n","        C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV = caches(P_old, Q_old)\n","        \n","        if learning_rate < threshold:\n","            new_loss = old_loss\n","            break\n","      \n","        rating_users = R[:,i]\n","        w_users = w_0*df_weightRead_matrix.values[:,i]\n","        user_list = np.where(rating_users == 1)[0]\n","\n","        click_users = C[:,i]\n","        user_click_list = np.where(click_users == 1)[0]\n","\n","        R_i = len(user_list)\n","        V_i = len(user_click_list)\n","        \n","        if R_i == 0:\n","            return\n","        \n","        ## prediction cache for the item\n","        for u in user_list:\n","            prediction_users[u] = np.dot(P[u], np.transpose(Q[i])) \n","\n","        ind_u = np.zeros(V_i, dtype=int)\n","        cnt = 0\n","        GRold = np.zeros(V_i)\n","        GvRold = np.zeros(V_i)\n","        LvRold = np.zeros(V_i)\n","        DVold = 0.\n","\n","        for u in user_click_list:\n","            ind_u[cnt] = u\n","            cnt += 1\n","            prediction_users[u] = np.dot(P[u], np.transpose(Q[i])) \n","            GR[u] = 0\n","            for k in range(factors):\n","                GR[u] += P[u,k] * DV[k]\n","                Told[k] = Told[k] - C_i[i] * P[u,k] * prediction_users[u]\n","\n","        old_vector = Q[i]\n","\n","        for f in range(factors):\n","            for n in range(V_i):\n","                GRold[n] = GR[ind_u[n]] - P[ind_u[n],f] * DV[f]\n","                GvRold[n] = GvR[ind_u[n]] - prediction_users[ind_u[n]]\n","                LvRold[n] = LvR[ind_u[n]] - C_i[i] * prediction_users[ind_u[n]]\n","            DVold = DV[f] - Q[i,f]\n","\n","            numer = 0.\n","            denom = 0.\n","\n","            for k in range(f):\n","                if k != f:\n","                    numer += Q[i,k] * EU[f,k] * S_i[i] \n","                    numer += Q[i,k] * HU[f,k]\n","\n","\n","            for u in user_list:\n","                prediction_users[u] -= P[u,f] * Q[i,f] #learning_rate *\n","                numer += -(w_users[u] * rating_users[u] - (w_users[u] - S_i[i]) * prediction_users[u]) * P[u,f]\n","                numer -= (gamma_1 + gamma_2) * C_u[u] * P[u,f]\n","                denom += (w_users[u] - S_i[i]) * P[u,f] * P[u,f]\n","\n","            denom += S_i[i] * EU[f,f] + HU[f,f] + reg\n","\n","            for u in user_click_list:\n","                prediction_users[u] -= P[u,f] * Q[i,f] #learning_rate *\n","                numer += -S_i[i] * prediction_users[u] * P[u,f] \n","                numer -= C_i[i] * GR[u] * P[u,f] \n","                numer += C_i[i] * GvR[u] * P[u,f] \n","                numer += LvR[u] * P[u,f]\n","                numer += C_i[i] * (prediction_users[u] * (number_of_items - V_u[u]) + (gamma_1 + gamma_2) * R_u[u] - gamma_2 * (number_of_items - V_u[u])) * P[u,f]\n","                numer -= (prediction_users[u] + gamma_2) * C_u[u] * P[u,f]\n","                denom += -S_i[i] * P[u,f]  * P[u,f] \n","                denom += C_i[i] * (number_of_items - V_u[u]) * P[u,f] * P[u,f] \n","                denom -= C_u[u] * P[u,f] * P[u,f]\n","\n","            numer += - T[f] + gamma_2 * DU[f]\n","\n","            #update = Q_old[i,f] - learning_rate * (Q_old[i,f] - numer/denom)\n","            update = -numer/denom\n","        #Update Factor\n","            if NN == True:\n","                if update >= 0:\n","                    Q[i,f] = update\n","                else:\n","                    Q[i,f] = 0\n","            else:\n","                Q[i,f] = update\n","\n","        #Update Prediction Cache\n","        for u in user_list:\n","            prediction_users[u] += P[u,f] * Q[i,f] # learning_rate *\n","\n","        for u in user_click_list:\n","            prediction_users[u] += P[u,f] * Q[i,f] # learning_rate *\n","            \n","        tf = 0.\n","        tfp1 = 0.\n","\n","        fp1 = f + 1\n","\n","        if fp1 >= factors:\n","            fp1 = 0\n","\n","        DV[f] = DVold + Q[i,f]\n","        for n in range(V_i):\n","            GR[ind_u[n]] = GRold[n] + P[ind_u[n],f] * DV[f]\n","            GvR[ind_u[n]] = GvRold[n] + prediction_users[ind_u[n]]\n","            LvR[ind_u[n]] = LvRold[n] + C_i[i] * prediction_users[ind_u[n]]\n","            tf += C_i[i] * P[ind_u[n],f] * prediction_users[ind_u[n]]\n","            tfp1 += C_i[i] * P[ind_u[n],fp1] * prediction_users[ind_u[n]]\n","\n","        Told[f] = T[f] - tf\n","        T[fp1] = Told[fp1] + tfp1\n","\n","        for u in user_click_list:\n","            for k in range(factors):\n","                Told[k] = Told[k] + C_i[i] * P[u,k] * prediction_users[u]\n","\n","        #Update Cache\n","        for f in range(factors):\n","            for k in range(f+1):\n","                val1 = EV[f,k] - old_vector[f] * old_vector[k] + Q[i,f] * Q[i,k]\n","                EV[f,k] = val1\n","                EV[k,f] = val1\n","\n","                val2 = HV[f,k] - old_vector[f] * old_vector[k] * S_i[i] + Q[i,f] * Q[i,k] * S_i[i]\n","                HV[f,k] = val2\n","                HV[k,f] = val2\n","                 \n","        new_loss = loss(C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q)\n","        diff_loss = old_loss - new_loss\n","                                              \n","        if diff_loss < 0. or new_loss < 0.:\n","            Q = np.copy(Q_old)\n","            iter=1\n","            \n","    return C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q, new_loss           "],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":1145049,"status":"ok","timestamp":1552067444140,"user":{"displayName":"Arno Claes","photoUrl":"","userId":"18358942717775719175"},"user_tz":-60},"id":"eaYC8J35Gvht","outputId":"6ebca805-b277-4c7c-f16f-bc612077ef8c","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1071}},"cell_type":"code","source":["thresh = 0.1\n","diffloss = 1\n","\n","#Top level iteration with stop criterion max epochs\n","C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV = caches(P, Q)\n","oldloss = loss(C_u, V_u, R_u, GR, GvR, LvR, T, Told, EU, DU, HU, EV, DV, HV, P, Q)\n","print(f'Start loss {oldloss}')\n","j = 0\n","\n","while abs(diffloss) > thresh or abs(iterloss) > thresh:\n","    epochloss = oldloss\n","    \n","    #Update client factors\n","    for u in range(number_of_clients):\n","        Pold, Qold = P, Q\n","        C_u_new, V_u_new, R_u_new, GR_new, GvR_new, LvR_new, T_new, Told_new, EU_new, DU_new, HU_new, EV_new, DV_new, HV_new, P_new, Q_new, newloss = update_user(P, Q, u, NN = False, old_loss = oldloss)\n","\n","        if newloss<oldloss:\n","            P, Q = P_new, Q_new\n","            oldloss = newloss\n","        elif oldloss == newloss:\n","            P, Q = P_new, Q_new\n","        elif oldloss<newloss:\n","            P, Q = Pold, Qold\n","    print(f'P_{j} loss {oldloss}')\n","    userloss = oldloss    \n","  #Update item factors\n","    for i in range(number_of_items):\n","        Pold, Qold = P, Q\n","        C_u_new, V_u_new, R_u_new, GR_new, GvR_new, LvR_new, T_new, Told_new, EU_new, DU_new, HU_new, EV_new, DV_new, HV_new, P_new, Q_new, newloss = update_user(P, Q, u, NN = False, old_loss = oldloss)\n","        \n","        if newloss<oldloss:\n","            P, Q = P_new, Q_new\n","            oldloss = newloss\n","        elif oldloss == newloss:\n","            P, Q = P_new, Q_new\n","        elif oldloss<newloss:\n","            P, Q = Pold, Qold\n","    print(f'Q_{j} loss {oldloss}')\n","    itemloss = oldloss\n","    diffloss = userloss - itemloss\n","    iterloss = epochloss - itemloss\n","    j += 1\n","\n","else:\n","    print(f'Convergence after {j} iterations')\n","  \n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Start loss 30836.71523591426\n","P_0 loss 8676.867864778875\n","Q_0 loss 8664.148861252264\n","P_1 loss 7250.682289480832\n","Q_1 loss 7250.679913710311\n","P_2 loss 6459.066772185218\n","Q_2 loss 6459.06676759225\n","P_3 loss 5985.673332635312\n","Q_3 loss 5985.673332626431\n","P_4 loss 5682.585255738954\n","Q_4 loss 5682.585255738937\n","P_5 loss 5475.3184233164875\n","Q_5 loss 5475.3184233164875\n","P_6 loss 5324.921566885269\n","Q_6 loss 5324.9215668852685\n","P_7 loss 5210.165903847287\n","Q_7 loss 5210.165903847286\n","P_8 loss 5118.967006881266\n","Q_8 loss 5118.967006881265\n","P_9 loss 5044.133099423666\n","Q_9 loss 5044.133099423666\n","P_10 loss 4981.189392956977\n","Q_10 loss 4981.189392956977\n","P_11 loss 4927.2266870847925\n","Q_11 loss 4927.2266870847925\n","P_12 loss 4880.271205047681\n","Q_12 loss 4880.271205047681\n","P_13 loss 4838.928443612464\n","Q_13 loss 4838.928443612464\n","P_14 loss 4802.175768867962\n","Q_14 loss 4802.175768867962\n","P_15 loss 4769.238205140455\n","Q_15 loss 4769.238205140455\n","P_16 loss 4739.512001700514\n","Q_16 loss 4739.512001700514\n","P_17 loss 4712.516268621896\n","Q_17 loss 4712.516268621896\n","P_18 loss 4687.861426881096\n","Q_18 loss 4687.861426881096\n","P_19 loss 4665.227908515673\n","Q_19 loss 4665.227908515673\n","P_20 loss 4644.351217240747\n","Q_20 loss 4644.351217240747\n","P_21 loss 4625.011020067439\n","Q_21 loss 4625.011020067439\n","P_22 loss 4607.022866333749\n","Q_22 loss 4607.022866333749\n","P_23 loss 4590.231685767814\n","Q_23 loss 4590.231685767814\n","P_24 loss 4574.506550899601\n","Q_24 loss 4574.506550899601\n","P_25 loss 4559.736388244552\n","Q_25 loss 4559.736388244552\n","P_26 loss 4545.826439365616\n","Q_26 loss 4545.826439365616\n","P_27 loss 4532.695339334421\n","Q_27 loss 4532.695339334421\n","P_28 loss 4520.272716500241\n","Q_28 loss 4520.272716500241\n","P_29 loss 4508.497236703672\n","Q_29 loss 4508.497236703672\n","P_30 loss 4497.315025262897\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"jfD8stPs12lG","colab":{}},"cell_type":"code","source":["R_est = np.dot(P,np.transpose(Q))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"Esj6cXJk12lJ","colab":{}},"cell_type":"code","source":["np.savez(\"/content/drive/My Drive/Knab/Data/CleanData/ALS_inputs/P_matrix_15.npz\",P)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"b5VLePOK12lO","colab":{}},"cell_type":"code","source":["np.savez(\"/content/drive/My Drive/Knab/Data/CleanData/ALS_inputs/Q_matrix_15.npz\", Q)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"6PZvDVvy12lS","colab":{}},"cell_type":"code","source":["for i in range(len(client_list)):\n","    read_articles = R[i]\n","    clicked_articles = C[i]\n","    for j in range(len(item_list)):\n","        if read_articles[j] == 1:\n","            R_est[i,j] = 0\n","        elif clicked_articles[j] == 1:\n","            R_est[i,j] = 0"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"fwlAW-E412lU","colab":{}},"cell_type":"code","source":["hitrate = np.zeros(len(range(3,11)))\n","cnt = 0\n","for j in range(3,11):\n","    test_item_loc = np.zeros(len(df_test_set), dtype= int) #location of items in R_est\n","    test_client_loc = np.zeros(len(df_test_set), dtype= int) #location of users in R_est\n","    test_R_est = np.zeros(len(df_test_set)) #estimated rating of user-item pair\n","    max_indices_test = [] #list for indices of top-N rated articles\n","\n","    hit = 0\n","    for i in range(len(df_test_set)):\n","        url = df_test_set.iloc[i]['URL'] #take url of row in test set\n","        clientid = df_test_set.iloc[i]['clientid_hashed'] #take clientid of row in test set\n","\n","        #Find location in list and value in estimated ratings\n","        test_item_loc[i] = item_list.index(url) #take index for the url\n","        test_client_loc[i] = client_list.index(clientid) #take index for the client\n","        user_ratings = R_est[test_client_loc[i]] #take ratings for this client\n","        test_R_est[i] = R_est[test_client_loc[i],test_item_loc[i]] #store rating for the client-item pair\n","\n","        #Find top-N rated articles in estimated ratings for users\n","        max_indices_test.append(user_ratings.argsort()[-j:][::-1]) #store top-n ratings of this client\n","        if test_item_loc[i] in max_indices_test[i]:\n","            hit += 1\n","    \n","    hitrate[cnt] = hit/len(df_test_set)\n","    max_indices_test =  np.array([max_indices_test])[0]\n","    cnt += 1"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"YQf6P7rV12lb","outputId":"2879f3e9-bf7e-49dc-9414-197942ca1c8c","colab":{}},"cell_type":"code","source":["hitrate"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.008     , 0.01066667, 0.01333333, 0.01333333, 0.01333333,\n","       0.01333333, 0.01333333, 0.01333333])"]},"metadata":{"tags":[]},"execution_count":188}]}]}